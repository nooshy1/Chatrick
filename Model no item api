# OSRS Quant Watchlist + Correlation Model (OSRS Wiki API Version)

# ðŸ“¦ Step 1: Install required packages (Colab will need these)
!pip install requests pandas scikit-learn matplotlib seaborn

# ðŸ“š Step 2: Import libraries
import requests
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.ensemble import IsolationForest
from sklearn.decomposition import PCA
from scipy.spatial import distance
import time

# ðŸ“Š Step 5: DataFrame & Modeling

df = pd.DataFrame(items)
features = ['spread', 'volatility', 'momentum']

# Clean and drop rows with NaNs in feature columns
df_clean = df.dropna(subset=features).copy()
X = StandardScaler().fit_transform(df_clean[features])

# KMeans clustering
kmeans = KMeans(n_clusters=3, random_state=42)
df_clean['cluster'] = kmeans.fit_predict(X)

# Isolation Forest for anomaly detection
iso = IsolationForest(contamination=0.2, random_state=42)
df_clean['anomaly'] = iso.fit_predict(X)
df_clean['anomaly'] = df_clean['anomaly'].map({1: 'normal', -1: 'anomaly'})

print("\nðŸŒŸ OSRS Watchlist - Anomalous Items:")
print(df_clean[df_clean['anomaly'] == 'anomaly'][['id', 'name', 'price', 'low', 'spread']])

# ðŸ”¹ Step 6: Correlation Analysis
price_matrix = pd.concat(price_history.values(), axis=1)
price_matrix.columns = list(price_history.keys())
correlation_matrix = price_matrix.pct_change().corr()
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, cmap='coolwarm', xticklabels=True, yticklabels=True)
plt.title("OSRS Item Price Correlation Heatmap")
plt.tight_layout()
plt.show()

# ðŸ“€ Step 7: Iterative PCA with Outlier Removal
filtered_matrix = price_matrix.copy()
outliers_exist = True
iteration = 1

while outliers_exist:
    print(f"\nIteration {iteration}: Performing PCA...")
    pca = PCA(n_components=2)
    reduced = pca.fit_transform(filtered_matrix.fillna(method='ffill').pct_change().dropna().T)
    pca_df = pd.DataFrame(reduced, columns=['PC1', 'PC2'])
    pca_df['Item'] = list(filtered_matrix.columns)

    # Mahalanobis distance calculation
    mean_vec = np.mean(reduced, axis=0)
    cov_matrix = np.cov(reduced.T)
    try:
        cov_inv = np.linalg.inv(cov_matrix)
    except np.linalg.LinAlgError:
        print("\nâš ï¸ Covariance matrix is singular. Terminating PCA loop.")
        break
    mahal_distances = [distance.mahalanobis(row, mean_vec, cov_inv) for row in reduced]
    pca_df['Mahalanobis'] = mahal_distances
    threshold = np.percentile(mahal_distances, 95)
    pca_df['Outlier'] = pca_df['Mahalanobis'] > threshold

    # Visualization
    plt.figure(figsize=(12, 8))
    ax = sns.scatterplot(x='PC1', y='PC2', data=pca_df, hue='Outlier', style='Outlier', palette={True: 'red', False: 'blue'}, s=60)
    for i, row in pca_df.iterrows():
        ax.text(row['PC1'], row['PC2'], row['Item'], fontsize=9, weight='bold', color='black' if not row['Outlier'] else 'red')
    plt.title(f"PCA Iteration {iteration}: Outlier Detection")
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)
    plt.tight_layout()
    plt.show()

    # Remove outliers
    if pca_df['Outlier'].any():
        filtered_items = pca_df[~pca_df['Outlier']]['Item']
        filtered_matrix = price_matrix[filtered_items]
        iteration += 1
    else:
        outliers_exist = False

# ðŸªœ Final core items after outlier removal
print("\nðŸ”¹ Final Core Items After All Outliers Removed:")
print(pca_df[~pca_df['Outlier']]['Item'].tolist())
